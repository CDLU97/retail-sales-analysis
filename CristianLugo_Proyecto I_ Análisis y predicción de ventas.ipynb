{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNa2alRsL6uCfynZiG4Q33O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"E39dDpilMmz_"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **Análisis y Predicción de Ventas en una Tienda de Retail (Core)**\n","\n","Parte 1: Análisis Básico con NumPy\n","\n","En esta primera parte del proyecto, los estudiantes realizarán un análisis preliminar del dataset utilizando NumPy. El objetivo es familiarizarse con los datos y realizar operaciones básicas de manipulación y análisis.\n","\n","# **Alumno:** Cristian Lugo"],"metadata":{"id":"zgQ0kW72MtQ0"}},{"cell_type":"code","source":["# Importar las bibliotecas necesarias\n","\n","import numpy as np      # Importamos la librería numpy\n","from datetime import datetime  # Importamos el objeto datetime del módulo datetime\n","\n","#El dataset ha sido descargado desde la Página de kaggle. Puedes encontrar el dataset en el siguiente link: https://www.kaggle.com/datasets/mohammadtalib786/retail-sales-dataset/data\n","# EL archivo ha sido descargado con el nombre: retail_sales_dataset.csv\n","\n","#Carga los datos del archivo CSV utilizando NumPy.\n","# Paso 1: Cargar el dataset desde un archivo local\n","# En este paso, cargamos el archivo CSV desde la carpeta donde se encuentra el dataset.\n","\n","from google.colab import files\n","# Esto abrirá una ventana para que selecciones el archivo en tu computadora\n","uploaded = files.upload()   # Habilita la opción para seleccionar el archivo a ser cargado\n","\n","file_name = next(iter(uploaded))  # Obtiene el nombre del primer archivo subido\n","data = np.genfromtxt(file_name, delimiter=',', dtype=None, names=True, encoding='utf-8') #Guarda los datos del archivo cargado en la variable datos\n","print(data) #Imprime los datos de la variable datos\n","\n","#Realiza un preprocesamiento básico para asegurarte de que los datos estén limpios y listos para su análisis.\n","\n","# Paso 2: Extracción de columnas necesarias\n","# Extraemos todas las columnas disponibles para trabajar con ellas directamente\n","transaction_ids = data['Transaction_ID']  # Columna de ID de transacción (entero)\n","dates = data['Date']                      # Columna de fechas (cadena de texto inicialmente)\n","customer_ids = data['Customer_ID']        # Columna de ID de cliente (cadena de texto)\n","genders = data['Gender']                  # Columna de género del cliente (cadena de texto)\n","ages = data['Age']                        # Columna de edad del cliente (entero)\n","categories = data['Product_Category']     # Columna de categoría de producto (cadena de texto)\n","quantities = data['Quantity']             # Columna de cantidad de productos comprados (entero)\n","prices_per_unit = data['Price_per_Unit']  # Columna de precio por unidad (flotante)\n","amounts = data['Total_Amount']            # Columna de montos totales (flotante)\n","\n","# Paso 3: Identificar categorías únicas\n","# np.unique devuelve un arreglo con las categorías únicas presentes en la columna\n","unique_categories = np.unique(categories)\n","\n","# Paso 4: Calcular el total de ventas por categoría\n","# Creamos un diccionario donde la clave es la categoría y el valor es la suma de los montos para esa categoría\n","sales_by_category = {\n","    category: np.sum(amounts[categories == category]) for category in unique_categories\n","}\n","\n","# Paso 5: Calcular el promedio de ventas diarias por categoría\n","# Convertimos las fechas del archivo a objetos datetime para facilitar su manipulación\n","dates_converted = np.array([datetime.strptime(d, '%Y-%m-%d') for d in dates])\n","\n","# Inicializamos un diccionario para almacenar el promedio de ventas diarias por categoría\n","average_sales_by_category = {}\n","for category in unique_categories:\n","    # Creamos una máscara booleana para filtrar datos de la categoría actual\n","    mask = categories == category\n","    filtered_dates = dates_converted[mask]  # Filtrar fechas por categoría\n","    filtered_amounts = amounts[mask]  # Filtrar montos por categoría\n","\n","    # Encontrar las ventas totales por día\n","    # Usamos np.unique para identificar fechas únicas y calcular las ventas diarias\n","    unique_days = np.unique(filtered_dates)\n","    daily_totals = [\n","        np.sum(filtered_amounts[filtered_dates == day]) for day in unique_days\n","    ]\n","\n","    # Calculamos el promedio de las ventas diarias para esta categoría\n","    average_sales_by_category[category] = np.mean(daily_totals)\n","\n","# Paso 6: Identificar categorías con mayores y menores ventas\n","# Convertimos las ventas totales en un arreglo para usar funciones de NumPy\n","total_sales_array = np.array(list(sales_by_category.values()))\n","max_category = unique_categories[np.argmax(total_sales_array)]  # Categoría con mayores ventas\n","min_category = unique_categories[np.argmin(total_sales_array)]  # Categoría con menores ventas\n","\n","# Resultados\n","# Imprimimos los resultados de los análisis realizados\n","print(\"Total de ventas por categoría:\", sales_by_category)\n","print(\"Promedio de ventas diarias por categoría:\", average_sales_by_category)\n","print(\"Categoría con mayores ventas:\", max_category)\n","print(\"Categoría con menores ventas:\", min_category)\n"],"metadata":{"id":"tG3TC1mzM_qs"},"execution_count":null,"outputs":[]}]}